---
title: "CS 562: Advanced Topics in Security, Privacy, and Machine Learning"
date: 2024-01-12
---

**Session-VC: Machine Learning for Sys, Networks, and Security**

[Home](https://chandrasekaran-group.github.io/courses/cs562/) | [Campuswire](#campuswire) | [Paper Signup Sheet](#papersignup) | [Project](https://chandrasekaran-group.github.io/courses/cs562/project/)

---

**Instructor**: [Varun Chandrasekaran](https://chandrasekaran-group.github.io/) (varunc@illinois.edu)

**TA**: [Qilong Wu](https://www.qilongwu.com/) (qilong3@illinois.edu)

**Time/Location**: Wednesday 03:00 - 06:00 PM. Siebel Center for Comp Sci Room 0216

**Office Hour**: By Appointment

---

> ### Announcement
> 
> 1/17/2024: [First week of class] Enrolled students will be added/invited to CS 562 Campuswire before the first week of the class. If you registered during/after the first week and did not get the Campuswire invitation, please email the instructor (varunc@illinois.edu) for the invitation code.

---

# Class Description

Advanced topics in security and privacy problems in machine learning systems, selected from areas of current research such as: This section will primarily focus on using machine learning for system, networking, and security applications. Example topics include using ML to build novel security defenses (e.g., detecting network intrusions, cybercrime, and disinformation, and performing user authentication and vulnerability analysis), launch novel attacks (e.g., privacy attacks, password guessing, deepfake-based social engineering), and support system optimizations. We will explore new research directions and seek to understand the limitations and potential risks of ML-based approaches. Students will read, present, and discuss research papers, and work on an original research project. The goal of the project is to extend machine learning techniques to new problems and produce publishable results.

---

# Expected Work

- **Reading**: students will be reading and reviewing all the required papers, and participating in paper discussions during the class and over the online discussion board.
- **Participation**: students are required to attend all the lectures. Please inform the instructor via email if you cannot make it to the class due to travel or sickness.
- **Team Project**: 3-4 students will form a team to work on a single research project throughout the semester. The project should aim to solve a real problem in the intersection area of machine learning and security/system. Each team will write a project proposal, perform literature surveys, give a short talk in the midterm, and give a final presentation at the end of the semester. Each team is also expected to write up a final project report.
- **Paper Presentation**: students will present papers during the class to lead the discussion.

All deadlines are 11:59 PM (CT) of the specific date (not including paper reviews).

---

# Class Schedule

| Week / Date | Papers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Deadline |
|-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|
| **Week 1:**<br>Jan 17 | Class overview and background introduction.<br>Attacking ML: evasion and poisoning<br>• Towards Evaluating the Robustness of Neural Networks SP 2017<br>• Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning SP 2018                                                                                                                                                                                                                                                                                  | Claim paper slot |
| **Week 2:**<br>Jan 24 | Attacking ML: backdoor<br>• Trojaning Attack on Neural Networks NDSS 2018<br>• Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks SP 2019<br>Attacking ML: problem-space constraints<br>• Intriguing Properties of Adversarial ML Attacks in the Problem Space SP 2020<br>• On the Robustness of Domain Constraints CCS 2021                                                                                                                                                                                        |  |
| **Week 3:**<br>Jan 31 | ML for security: e-crime<br>• Detecting Credential Spearphishing in Enterprise Settings USENIX Security 2017<br>• Boxer: Preventing fraud by scanning credit cards USENIX Security 2020<br>ML for security: phishing<br>• VisualPhishNet: Zero-Day Phishing Website Detection by Visual Similarity CCS 2020<br>• Inferring Phishing Intention via Webpage Appearance and Dynamics: A Deep Vision Based Approach USENIX Security 2022                                                                                                            |  |
| **Week 4:**<br>Feb 7  | ML for security: binary code analysis<br>• Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection CCS 2017<br>• PalmTree: Learning an Assembly Language Model for Instruction Embedding CCS 2021<br>ML for security: code and authorship<br>• De-anonymizing Programmers via Code Stylometry USENIX Security 2015<br>• Large-Scale and Language-Oblivious Code Authorship Identification CCS 2018                                                                                                             | Project proposal |
| **Week 5:**<br>Feb 14 | ML for security: network intrusion<br>• Outside the Closed World: On Using Machine Learning for Network Intrusion Detection SP 2010<br>• Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection NDSS 2018<br>ML for security: evaluation and biases<br>• TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time USENIX Security 2019<br>• Dos and Don'ts of Machine Learning in Computer Security USENIX Security 2022                                                                   |  |
| **Week 6:**<br>Feb 21 | ML for security: concept drift<br>• Transcend: Detecting Concept Drift in Malware Classification Models USENIX Security 2017<br>• Continuous Learning for Android Malware Detection USENIX Security 2023<br>ML for attack: password guessing<br>• Fast, Lean, and Accurate: Modeling Password Guessability Using Neural Networks USENIX Security 2016<br>• Beyond Credential Stuffing: Password Similarity Models using Neural Networks SP 2019                                                                                                 |  |
| **Week 7:**<br>Feb 28 | **Midterm project presentation** <br>ML explanation<br>• "Why Should I Trust You?": Explaining the Predictions of Any Classifier KDD 2016<br>• A Unified Approach to Interpreting Model Predictions NeurIPS 2017<br>ML explanation: limitations<br>• Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization ICCV 2017<br>• Towards A Rigorous Science of Interpretable Machine Learning Arxiv 2017<br>• Interpretable Deep Learning under Fire USENIX Security 2020<br>• Sanity Checks for Saliency Maps NeurIPS 2018 | Midterm report due |
| **Week 8:**<br>Mar 2  | Explanation vs. malware backdoor<br>• Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers USENIX Security 2021<br>• Disguising Attacks with Explanation-Aware Backdoors SP 2023<br>ML for security: deepfake<br>• MARLIN: Masked Autoencoder for facial video Representation LearnINg CVPR 2023<br>• Exposing GAN-Generated Profile Photos From Compact Embeddings CVPR workshop 2023                                                                                                                                     |  |
| **Week 9:**<br>Mar 9  | Spring Break                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |  |
| **Week 10:**<br>Mar 16 | Spring Break                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |  |
| **Week 11:**<br>Mar 23 | LLM abuse<br>• Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection Arxiv 2023<br>• Analyzing Leakage of Personally Identifiable Information in Language Models SP 2023<br>LLM and code<br>• Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions SP 2022<br>• Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants USENIX Security 2023                                                                  |  |
| **Week 12:**<br>Mar 30 | Attacking ML: privacy/copyright<br>• Fawkes: Protecting Privacy against Unauthorized Deep Learning Models USENIX Security 2020<br>• Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models USENIX Security 2023<br>Attacking ML: perceptions<br>• AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning CCS 2019<br>• Squint Hard Enough: Attacking Perceptual Hashing with Adversarial Machine Learning USENIX Security 2023                                                                                    | Progress update slides |
| **Week 13:**<br>Apr 6  | ML and networks: Tor<br>• DeepCorr: Strong Flow Correlation Attacks on Tor Using Deep Learning CCS 2018<br>• Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations USENIX Security 2021<br>ML and networks: data generation<br>• Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions IMC 2020<br>• Practical GAN-based Synthetic IP Header Trace Generation using NetShare SIGCOMM 2022                                                                 |  |
| **Week 14:**<br>Apr 13 | ML explanation for networks<br>• XNIDS: Explaining Deep Learning-based Network Intrusion Detection Systems for Active Intrusion Responses USENIX Security 2023<br>• AI/ML for Network Security: The Emperor has no Clothes CCS 2022<br>Human + ML for security<br>• Rise of the HaCRS: Augmenting Autonomous Cyber Reasoning Systems with Human Assistance CCS 2017<br>• DEEPCASE: Semi-Supervised Contextual Analysis of Security Events SP 2022                                                                                               |  |
| **Week 15:**<br>Apr 20 | ML vs. authentication<br>• Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era USENIX Security 2022<br>• DepthFake: Spoofing 3D Face Authentication with a 2D Photo SP 2023<br>ML for security: binary code (advanced)<br>• DEEPDI: Learning a Relational Graph Convolutional Network Model on Instructions for Fast and Accurate Disassembly USENIX Security 2022<br>• XDA: Accurate, Robust Disassembly with Transfer Learning NDSS 2021                                                            |  |
| **Week 16:**<br>Apr 27 | Work on your final project, no class meeting                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |  |
| **Week 17:**<br>May 3-10 | Final exam week: project presentation in class + final report due                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |  |




# Grading

- Class attendance and participation: `5%`
- Paper reviews: `25%`
- Paper presentation in class: `15%`
- Project: proposal: `10%`
- Project: midterm presentation: `10%`
- Project: final presentation: `15%`
- Project: midterm report + progress update slides: `10%`
- Project: final report: `10%`

To calculate final grades, I simply sum up the points obtained by each student (the points will sum up to some number x out of 100) and then use the following scale to determine the letter grade: [0-60] F, [60-62] D-, [63-66] D, [67-69] D+, [70-72] C-, [73-76] C, [77-79] C+, [80-82] B-, [83-86] B, [87-89] B+, [90-92] A-, [93-100] A.
# Paper Review

We read two papers before each class meeting. Before each class, students are expected to read both papers and submit a short review via Campuswire. The deadline for the review is 3:00 PM (CT) on the day of class.

The review should contain sufficient content (about 200-500 words; it can be longer if needed). The review can focus on the key contributions of the paper, the strengths and weaknesses, or potential issues with the experiment methodologies and results. You can also discuss the practical implications of the paper and suggest new ideas. The review should reflect your own thoughts. All the students will post the reviews under the given paper's Campuswire thread. If you are the first to review the paper, you get to summarize the paper and comment on the key contributions. Other students who come later should avoid repeating the same arguments/comments that the previous reviews have already covered. Each review needs to have some original comments that are different from others.

# Policies

## Late Policy
All the deadlines are hard deadlines. Any late submissions will be subject to point reduction. For paper reviews, and project-related assignments: submitting within 3 days (72 hours) after the deadline = 60% of the points. This policy does not apply to the final project report, for which a late submission is not allowed.

## Academic Integrity
Students must follow the university's guidelines on academic conduct ([quick link](https://provost.illinois.edu/policies/policies/academic-integrity/students-quick-reference-guide-to-academic-integrity/)). This course will have a zero-tolerance policy regarding plagiarism. You (or your team) should complete all the assignments and project tasks on your own. When you use the code or tools developed by other people, please acknowledge the source. If an idea or a concept used in your project has been proposed by others, please make the proper citations. All electronic work submitted for this course will be archived and subjected to automatic plagiarism detection. Whenever in doubt, please seek clarifications from the instructor. Students who violate Academic Integrity policies will be immediately reported to the department and the college.

When presenting research papers in the class, you may NOT use the authors' slides directly. Please make your own slides.

## Special Accommodations
If you need special accommodations because of a disability, please contact the instructor in the first week of classes.

## Diminished Mental Health
Diminished mental health, including significant stress, mood changes, excessive worry, substance/alcohol abuse, or problems with eating and/or sleeping can interfere with optimal academic performance, social development, and emotional wellbeing. The University of Illinois offers a variety of confidential services including individual and group counseling, crisis intervention, psychiatric services, and specialized screenings at no additional cost. If you or someone you know experiences any of the above mental health concerns, it is strongly encouraged to contact or visit any of the University’s resources provided below. Getting help is a smart and courageous thing to do -- for yourself and for those who care about you.

- **Counseling Center**: 217-333-3704, 610 East John Street Champaign, IL 61820
- **McKinley Health Center**: 217-333-2700, 1109 South Lincoln Avenue, Urbana, Illinois 61801



